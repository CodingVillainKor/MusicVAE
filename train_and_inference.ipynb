{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Load dataset\n",
        "#### Generated from preprocess.py"
      ],
      "metadata": {
        "id": "jqRPT_P5D65b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle as pkl\n",
        "with open(\"dataset.pkl\", \"rb\") as fr:\n",
        "    dataset = pkl.load(fr)\n",
        "print(f\"len(dataset) = {len(dataset):,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqP8tTMMCOrO",
        "outputId": "a4a80f3a-4c06-4e8c-c6f9-095bd5d2fdef"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(dataset) = 3,897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model.py"
      ],
      "metadata": {
        "id": "ceaS7aOLTN-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, lstm_first, lstm_second, latent_Wmu, latent_Wsig):\n",
        "        super().__init__()\n",
        "        self.lstm_first = nn.LSTM(**lstm_first)\n",
        "        self.lstm_second = nn.LSTM(**lstm_second)\n",
        "        self.latent_Wmu = nn.Linear(**latent_Wmu)\n",
        "        self.latent_Wsig = nn.Linear(**latent_Wsig)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        B = x.shape[0]\n",
        "        o, (h_1, c) = self.lstm_first(x)\n",
        "        o, (h, c) = self.lstm_second(o)\n",
        "        h = h.permute(1, 0, 2).reshape(B, -1) # 2 B H > B 2 H > B (2H)\n",
        "        mu = self.latent_Wmu(h)\n",
        "        sig = F.softplus(self.latent_Wsig(h), threshold=5) # (7)\n",
        "\n",
        "        return mu, sig\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 W_cond_init_state, lstm_conductor, \n",
        "                 W_dec_init_state, lstm_decoder,\n",
        "                 num_conductor_out, num_decoder_out,\n",
        "                 token_embedding, W_dist_out,\n",
        "                 sampling_strategy = \"argmax\",\n",
        "                 training_strategy = \"scheduled\"):\n",
        "        super().__init__()\n",
        "        self.W_cond_init_state = nn.Sequential(nn.Linear(**W_cond_init_state), nn.Tanh())\n",
        "        self.lstm_conductor = nn.LSTM(**lstm_conductor)\n",
        "        self.W_dec_init_state = nn.Sequential(nn.Linear(**W_dec_init_state), nn.Tanh())\n",
        "        self.lstm_decoder = nn.LSTM(**lstm_decoder)\n",
        "        self.embedding = nn.Embedding(**token_embedding)\n",
        "        self.dist_out_layer = nn.Sequential(nn.Linear(**W_dist_out), nn.Softmax())\n",
        "\n",
        "        self.conductor_hidden_size = lstm_conductor[\"hidden_size\"]\n",
        "        self.num_conductor_out = num_conductor_out\n",
        "        self.num_decoder_out = num_decoder_out\n",
        "        self.sampling_strategy = sampling_strategy\n",
        "        self.training_strategy = training_strategy\n",
        "\n",
        "    def forward(self, z, x=None, eps=0.):\n",
        "        conductor_in = self.W_cond_init_state(z)\n",
        "        conductor_out = self.get_conductor_out(conductor_in)\n",
        "        states = self.W_dec_init_state(conductor_out)\n",
        "        if x is not None: # teacher forcing\n",
        "            if self.training_strategy == \"scheduled\":\n",
        "                out = self.decoder_rnn_ss(states, x, eps) # distributions\n",
        "            else: # teacher forcing\n",
        "                out = self.decoder_rnn_tf(states, x) # distributions\n",
        "        else: # feedback generation\n",
        "            out = self.decoder_rnn_fg(states) # indices\n",
        "        return out\n",
        "\n",
        "    def get_conductor_out(self, conductor_in):\n",
        "        B, D = conductor_in.shape\n",
        "        h = conductor_in[:, :D//2]\n",
        "        h1, h2 = h[:, :D//4], h[:, D//4:]\n",
        "        h = torch.stack((h1, h2), 0)\n",
        "        c = conductor_in[:, D//2:]\n",
        "        c1, c2 = c[:, :D//4], c[:, D//4:]\n",
        "        c = torch.stack((c1, c2), 0)\n",
        "        outs = []\n",
        "        start = torch.zeros((B, 1, D//4), \n",
        "                            dtype=conductor_in.dtype,\n",
        "                            device=conductor_in.device)\n",
        "        o = start\n",
        "        for i in range(self.num_conductor_out):\n",
        "            o, (h, c) = self.lstm_conductor(o, (h, c))\n",
        "            outs.append(o)\n",
        "        out = torch.cat(outs, 1)\n",
        "        return out\n",
        "    \n",
        "    def decoder_rnn_tf(self, decoder_in, x):\n",
        "        B, U, D = decoder_in.shape # U is the number of bars\n",
        "        Bx, L = x.shape \n",
        "        assert D % 4 == 0\n",
        "        assert L % U == 0\n",
        "        decoder_in = decoder_in.view(-1, D) # B U D > (BU) D\n",
        "        x = x.view(Bx*U, L//U) # B L > (BU) (L/U) # (B*4) (64/4)\n",
        "        h = decoder_in[:, :D//2]\n",
        "        h1, h2 = h[:, :D//4], h[:, D//4:]\n",
        "        h = torch.stack((h1, h2), 0)\n",
        "        c = decoder_in[:, D//2:]\n",
        "        c1, c2 = c[:, :D//4], c[:, D//4:]\n",
        "        c = torch.stack((c1, c2), 0)\n",
        "        outs = []\n",
        "        emb_init = torch.zeros([Bx*U, 1, D//4],\n",
        "                               dtype=decoder_in.dtype,\n",
        "                               device=decoder_in.device)\n",
        "        emb = self.embedding(x)\n",
        "        emb = torch.cat((emb_init, emb[:, :-1]), 1)\n",
        "        h_init = h.clone().sum(0)[:, None] # 2 (BU) D > (BU) 1 D # no info about sum\n",
        "        emb = torch.cat((emb, h_init.repeat(1, emb.shape[1], 1)), -1)\n",
        "        o, (h, c) = self.lstm_decoder(emb, (h, c))\n",
        "        o = self.dist_out_layer(o)\n",
        "\n",
        "        o_unfolded = o.reshape(B, L, -1)\n",
        "        \n",
        "        return o_unfolded\n",
        "\n",
        "    def decoder_rnn_fg(self, decoder_in):\n",
        "        B, U, D = decoder_in.shape # U is the number of bars\n",
        "        assert D % 4 == 0\n",
        "        decoder_in = decoder_in.view(-1, D) # B U D > (BU) D\n",
        "        h = decoder_in[:, :D//2]\n",
        "        h1, h2 = h[:, :D//4], h[:, D//4:]\n",
        "        h = torch.stack((h1, h2), 0)\n",
        "        c = decoder_in[:, D//2:]\n",
        "        c1, c2 = c[:, :D//4], c[:, D//4:]\n",
        "        c = torch.stack((c1, c2), 0)\n",
        "        outs = []\n",
        "        emb = torch.zeros([B*U, 1, D//4], \n",
        "                          dtype=decoder_in.dtype,\n",
        "                          device=decoder_in.device)\n",
        "        h_init = h.clone().sum(0)[:, None] # 2 (BU) D > (BU) 1 D # no info about sum\n",
        "        for i in range(self.num_decoder_out):\n",
        "            o_in = torch.cat((emb, h_init), -1)\n",
        "            o, (h, c) = self.lstm_decoder(o_in, (h, c))\n",
        "            o = self.dist_out_layer(o)\n",
        "            emb, indices = self.sample_from_dist(o)\n",
        "            outs.append(indices)\n",
        "        out = torch.cat(outs, 1)\n",
        "        out_unfolded = out.view(B, U*self.num_decoder_out, -1)\n",
        "        return out_unfolded\n",
        "\n",
        "    def decoder_rnn_ss(self, decoder_in, x, eps):\n",
        "        # 1) with torch.no_grad(), get x_hat indices\n",
        "        # 2) random mixing\n",
        "        # 3) decoder_rnn_tf with mixedsample\n",
        "        with torch.no_grad():\n",
        "            hat_dist = self.decoder_rnn_tf(decoder_in, x)\n",
        "            _, hat_indices = self.sample_from_dist(hat_dist)\n",
        "            mixed_x = self.scheduled_sampling(x, hat_indices, eps)\n",
        "\n",
        "        out = self.decoder_rnn_tf(decoder_in, mixed_x)\n",
        "        return out\n",
        "\n",
        "    def scheduled_sampling(self, x, x_hat, eps):\n",
        "        B, L = x.shape\n",
        "        device = x.device\n",
        "        candidate = torch.cat((x, x_hat), -1) # 0: True, 1: hat\n",
        "        coins = torch.empty(B, L, device=device).fill_(eps) # eps==0: all-True, eps==1: all-hat\n",
        "        result = torch.bernoulli(coins).to(int)\n",
        "        \n",
        "        sampled = torch.gather(candidate, -1, result)\n",
        "        return sampled\n",
        "\n",
        "    def sample_from_dist(self, dist):\n",
        "        if self.sampling_strategy == \"argmax\":\n",
        "            indices = torch.argmax(dist, dim=-1)\n",
        "            emb = self.embedding(indices)\n",
        "            return emb, indices\n",
        "        elif self.sampling_strategy == \"multinomial\":\n",
        "            B, L, D = dist.shape\n",
        "            dist_folded = dist.view(B*L, D)\n",
        "            indices = torch.multinomial(dist_folded, 1) # (BL) 1\n",
        "            indices = indices.view(B, L)\n",
        "            emb = self.embdding(indices)\n",
        "            return emb, indices\n",
        "\n",
        "\n",
        "class MusicVAE(nn.Module):\n",
        "    def __init__(self, embedding, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(**embedding)\n",
        "        self.enc = Encoder(**encoder)\n",
        "        self.dec = Decoder(**decoder)\n",
        "    \n",
        "    def forward(self, x=None, z=None, mode=\"train\", eps=0.5):\n",
        "        if mode == \"train\":\n",
        "            embed_out = self.emb(x)\n",
        "            mu, sig = self.enc(embed_out)\n",
        "            z_reparam = self.z_reparam(mu, sig)\n",
        "            x_hat = self.dec(z_reparam, x=x) # x_hat: dist\n",
        "        elif mode == \"generate\":\n",
        "            x_hat = self.dec(z) # x_hat: indices(sampled from dist)\n",
        "        else: raise TypeError(\"Unknown mode\")\n",
        "        \n",
        "        out = x_hat if mode == \"generate\" else (x_hat, mu, sig)\n",
        "        return out\n",
        "\n",
        "    def z_reparam(self, mu, sig):\n",
        "        eps = torch.randn_like(mu, requires_grad=False)\n",
        "        \n",
        "        z_reparam = mu + sig*eps\n",
        "        return z_reparam"
      ],
      "metadata": {
        "id": "Lp28QvMFL_1Z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For Test/Debug\n",
        "\n",
        "* If you do not want to test model, do \"test_for_debug := False\""
      ],
      "metadata": {
        "id": "skZofUElkuP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if test_for_debug := False:\n",
        "    device = torch.device(\"cuda\") if torch.cuda.is_available else torch.device(\"cpu\")\n",
        "    test_x = torch.randint(128, [10, 256], device=device)\n",
        "    test_z = torch.randn([10, 512], device=device)\n",
        "    %load_ext autoreload\n",
        "    %autoreload 2\n",
        "    from config import model_config\n",
        "    model = MusicVAE(**model_config).to(device)\n",
        "    out_tf, mu, sig = model(x = test_x, eps=0.5)\n",
        "    out_fg = model(z = test_z, mode=\"generate\")"
      ],
      "metadata": {
        "id": "37IaEl6b1tR2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataloader, Model, Optimizer, LRscheduler"
      ],
      "metadata": {
        "id": "hHzxwlLkoMNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "from config import model_config\n",
        "\n",
        "def col_fn(batch_list):\n",
        "    batch = torch.stack([torch.tensor(item) for item in batch_list])\n",
        "    return batch\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available else torch.device(\"cpu\")\n",
        "model = MusicVAE(**model_config)\n",
        "dl = DataLoader(dataset, batch_size=64, shuffle=True, collate_fn=col_fn) # b 512 but\n",
        "opt = Adam(model.parameters(), lr=1e-3)\n",
        "lr_sch = ExponentialLR(opt, gamma=0.9999) \n",
        "lr_sch.last_epoch = 46049 # 5.1. 3. 1 (0.9999**n==0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oElRxp7DoLr5",
        "outputId": "a79184ef-359d-4542-f62b-bea3d4467dc0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss function"
      ],
      "metadata": {
        "id": "2A5bHv7rvCnc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.distributions.normal import Normal\n",
        "from torch.distributions.kl import kl_divergence\n",
        "\n",
        "def recon_loss(x_hat, x):\n",
        "    return F.nll_loss(torch.log(x_hat).permute(0,2,1), x)\n",
        "\n",
        "def kl_loss(mu, sigma, beta, free_bits): # 5.2. 1. 2\n",
        "    device = mu.device\n",
        "    mu_p  = torch.tensor([0.], device=device)\n",
        "    sig_p = torch.tensor([1.], device=device)\n",
        "    p_dist = Normal(mu_p, sig_p)\n",
        "    q_dist = Normal(mu, sigma)\n",
        "\n",
        "    kl_div = kl_divergence(q_dist, p_dist)\n",
        "    free_bits_tensor = torch.tensor([free_bits], device=device)\n",
        "    zero = torch.tensor([0.], device=device)\n",
        "    kl_loss = - beta * torch.max(torch.mean(kl_div)-free_bits, zero)\n",
        "\n",
        "    return kl_loss\n",
        "\n",
        "def loss_fn(x_hat, x, mu, sigma, beta, free_bits=48.):\n",
        "    reconstruction_loss = recon_loss(x_hat, x)\n",
        "    kl_div_loss = kl_loss(mu, sigma, beta, free_bits)\n",
        "\n",
        "    return reconstruction_loss + kl_div_loss\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oRDv0TQQvDKY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "# beta for beta-VAE \n",
        "def get_beta(idx):\n",
        "    return 2. - 2.0 * 0.99999 ** idx # 5.2. 1. 2\n",
        "\n",
        "# epsilon for scheduled sampling coefficient\n",
        "def get_epsilon(idx, k_rate=2000):\n",
        "    # inverse sigmoid\n",
        "    eps = k_rate / (k_rate+math.exp(idx/k_rate))\n",
        "    return eps"
      ],
      "metadata": {
        "id": "qRU4wzM2onXu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if is_train := False:\n",
        "    model = model.to(device)\n",
        "    idx = 0\n",
        "    for e in range(10):\n",
        "        model.train()\n",
        "        for x in dl:\n",
        "            opt.zero_grad()\n",
        "            x = x.to(device)\n",
        "            eps = get_epsilon(idx)\n",
        "            x_hat, mu, sigma = model(x, mode=\"train\", eps=eps)\n",
        "\n",
        "            beta = get_beta(idx)\n",
        "            loss = loss_fn(x_hat, x, mu, sigma, beta)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            lr_sch.step()\n",
        "            idx += 1\n",
        "            print(f\"\\riter: {idx:,} / loss = {loss.item():.3f}\", end='')\n",
        "    torch.save(model.state_dict(), \"checkpoint.ckpt\")"
      ],
      "metadata": {
        "id": "nHfT0TXaazas"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if is_generation := True:\n",
        "    ckpt_path = \"drive/MyDrive/Colab Notebooks/1850.ckpt\"\n",
        "    model.load_state_dict(torch.load(ckpt_path))\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        z = torch.randn([1, 512], device=device)\n",
        "        generated = model(z=z, mode=\"generate\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_v9L0lvlHW_e",
        "outputId": "afc06de4-fdd0-49d2-c62a-f26c1491f739"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py:204: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated = generated.detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "yUmAcmI6Jkfl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generated[0, :, 0].tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixP14Bjj532P",
        "outputId": "dbe5dcac-ed21-445a-ffd2-1be89f224d2a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[384, 192, 384, 192, 192, 384, 192, 128, 80, 272, 192, 384, 80, 384, 192, 128, 328, 17, 336, 273, 465, 273, 65, 273, 273, 81, 273, 81, 17, 17, 273, 273, 325, 256, 5, 69, 161, 64, 161, 69, 225, 261, 352, 481, 0, 385, 0, 65, 6, 98, 2, 102, 100, 274, 98, 98, 98, 98, 98, 98, 98, 98, 2, 100]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pretty_midi\n",
        "!pip install pyfluidsynth\n",
        "from to_midi import get_midi_from_profile"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "217TQckDDd28",
        "outputId": "3ce5b782-5d3f-4a01-edd3-86306782ecda"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pretty_midi in /usr/local/lib/python3.8/dist-packages (0.2.9)\n",
            "Requirement already satisfied: mido>=1.1.16 in /usr/local/lib/python3.8/dist-packages (from pretty_midi) (1.2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from pretty_midi) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from pretty_midi) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyfluidsynth in /usr/local/lib/python3.8/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pyfluidsynth) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "midi = get_midi_from_profile(generated[0, :, 0].tolist())\n",
        "midi.write(\"gen.mid\")"
      ],
      "metadata": {
        "id": "h-0HgusITTY_"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}